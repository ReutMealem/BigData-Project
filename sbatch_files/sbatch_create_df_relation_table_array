#!/bin/bash
#SBATCH --partition main                         # Partition name
#SBATCH --time 5-11:30:00                        # Job time limit
#SBATCH --job-name sql_query_array               # Job name
#SBATCH --output my_job-id-%A_%a.out             # Output log (%A: Job Array ID, %a: Task ID)
#SBATCH --mail-user=reutme@post.bgu.ac.il        # Email for notifications
#SBATCH --mail-type=END,FAIL                     # Notification types
#SBATCH --gpus=0
#SBATCH --mem=128G                               # Memory allocation
#SBATCH --cpus-per-task=15                       # CPUs per task
#SBATCH --array=0-23                            # Array indices (one for each SQL query)

### Print SLURM variables
echo "SLURM_JOBID=$SLURM_JOBID"
echo "SLURM_ARRAY_TASK_ID=$SLURM_ARRAY_TASK_ID"

### Activate the Conda environment
module load anaconda
source activate muscle_diff

### Execute Python script with the array index
python /home/reutme/Big_data/final_project/create_df_relation_table.py $SLURM_ARRAY_TASK_ID
